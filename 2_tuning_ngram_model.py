# -*- coding: utf-8 -*-
"""Bayan_khateeb_Pset_2_Tuning_ngram_model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/177vgeN3lVamRTJWCsEGhng3ddKIVq_08

This executable notebook will help you complete parts of Pset 2:

1. Introductory code for making plots in Python;
2. Scaffolding code for the $n$-gram model tuning problem.

If you haven't used Colab before, it's very similar to Jupyter / IPython / R Notebooks: cells containing Python code can be interactively run, and their outputs will be interpolated into this document. If you haven't used any such software before, we recommend [taking a quick tour of Colab](https://colab.research.google.com/notebooks/basic_features_overview.ipynb).

---

Now, a few Colab-specific things to note about execution before we get started:

- Google offers free compute (including GPU compute!) on this notebook, but *only for a limited time*. Your session will be automatically closed after 12 hours. That means you'll want to finish within 12 hours of starting, or make sure to save your intermediate work (see the next bullet).
- You can save and write files from this notebook, but they are *not guaranteed to persist*. For this reason, we'll mount a Google Drive account and write to that Drive when any files need to be kept permanently (e.g. model checkpoints, surprisal data, etc.).
- You should keep this tab open until you're completely finished with the notebook. If you close the tab, your session will be marked as "Idle" and may be terminated.

# Getting started

**First**, make a copy of this notebook so you can make your own changes. Click *File -> Save a copy in Drive*.

### What you need to do

Read through this notebook and execute each cell in sequence, making modifications and adding code where necessary. You should execute all of the code as instructed, and make sure to write code or textual responses wherever the text **TODO** shows up in text and code cells.

When you're finished, download the notebook as a PDF file by running the script in the last cell, or alternatively download it as an .ipynb file and locally convert it to PDF.

# Making plots in python

This code may help you with Part 2 of the "Tuning an $n$-gram language model" problem (plotting validation-set perplexity against test-set perplexity as a function of the additive smoothing parameter $\alpha$).
"""

# import relevant libraries
import matplotlib.pyplot as plt
import seaborn as sns; sns.set(style="white", color_codes=True)

x_variable = [1,2,3,4]
y_variable = [3,5,4,7]
sns.lineplot(x=x_variable,y=y_variable,marker='o') # marker='o' adds points to the line graph

"""The first thing that you see in the output, `<matplotlib.axes._subplots.AxesSubplot at 0x7f68a607e550>` (the hexadecimal number at the end may be different for you), is a string representation of the return value of the last line of code in the code cell.  In `seaborn`, the return value of plotting statements like `lineplot()`, is an object that can be subsequently modified to change the plot. In the below example, we assign this return value to a variable name, and then change the object to enrich the graph, using the `set()` method. We aren't interested in holding on to the return value of the `set() method, so to suppress the output of its string representation, we use a common Python convention of assigning it to the `_` variable (see e.g. Part 5 of [this nice article](https://medium.com/python-features/naming-conventions-with-underscores-in-python-791251ac7097)).  """

p = sns.lineplot(x=x_variable,y=y_variable,marker='o')
_ = p.set(xlabel="x",ylabel="y",xlim=(0,5),ylim=(0,8))

"""For multiple lines on the same plot in `seaborn`, you'll want to use `pandas`, which you are probably familiar with from previous Python experience.  The `melt()` function is extremely useful for getting your data into the right format."""

import pandas as pd
dat = pd.DataFrame({
    'x': x_variable,
    'y1': y_variable,
    'y2': [7,6,5,4]
})
print(dat)
pd.melt(dat,['x']) # we leave this at the bottom of the cell so you can see what melt() does

_ = sns.lineplot(x='x',y='value',hue='variable',data=pd.melt(dat,['x']))

"""# Tuning an $n$-gram model

The following is scaffolding code that you can expand to complete the problem.  First, we set up the training, validation, and test datasets (for real-size modeling problems you would read these from files):
"""

training_set = [['dogs', 'chase', 'cats'],
['dogs', 'bark'],
['cats', 'meow'],
['dogs', 'chase', 'birds'],
['birds', 'chase', 'cats'],
['dogs', 'chase', 'the', 'cats'],
['the', 'birds', 'chirp']]

validation_set = [['the','cats','meow'],
                  ['the','dogs','bark'], 
                  ['the','dogs','chase','the','cats']]

test_set = [['cats','meow'],['dogs','chase','the','birds']]

"""A natural way to implement a model is often to define a class that you can give model hyper-parameters, and define methods for training the model, computing the most basic building-block quantity relevant for the model, and assessing overall performance of a trained model on a dataset.  Below is scaffolding code for doing this.  For a bigram model, the most elementary quantity is $p(w_i|w_{i-1})$ so that is what the `prob()` method gives.

You don't need to use this scaffolding code in your solution to the problem, but you may find it useful.
"""

##TODO
class bigram_model:
  def __init__(self,alpha):
    self.alpha = alpha
    self.count_word={}
    self.count_pairs={}

  def train(self,training_set):
    # your code goes here
    n=len(training_set)
    self.count_word["<s>"]=n
    self.count_word["</s>"]=n
    for text in training_set:
      temp_text=["<s>"]+text+["</s>"]
      for word in text:
        for i in range(len(temp_text)-1):
          temp_pairs=(temp_text[i],temp_text[i+1])
          if temp_pairs in self.count_pairs: 
            self.count_pairs[temp_pairs]+=1
          else:
               self.count_pairs[temp_pairs]=1
      if word in self.count_word:
        self.count_word[word]+=1
      else:
        self.count_word[word]=1      
    
  
  def prob(self,previous_word,next_word):
    # your code goes here
    V=len(self.count_word)
    if (previous_word,next_word) not in self.count_pairs or previous_word not in self.count_word or V==0 :
      return 1/V #try 1/V another time
    else:
       return((self.count_pairs[previous_word,next_word]+self.alpha)/(self.count_word[previous_word]+self.alpha*V))
    

  def perplexity(self,heldout_set):
    # your code goes here
    p=1
    N=0
    for text in heldout_set: 
      temp_text=["<s>"]+text+["</s>"]
      for i in range(len(temp_text)-1): 
        p=p*self.prob(temp_text[i],temp_text[i+1])
        N=N+1
    return((p)**(-1/N)) # you'll change what the method returns

"""For step 1 of this problem, you need to find the value of $\alpha$ that optimizes validation-set perplexity; this is a simple example of what in machine learning these days "hyperparameter tuning" or "[hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)"."""

##TODO: your code for step 1 goes here
alphas = [i/1000 for i in range(1,101)]
prex=[]
for alpha in alphas:
  model=bigram_model(alpha)
  model.train(training_set)
  prex.append(model.perplexity(training_set))

min(prex)

"""For step 2, write a function which returns the perplexities of the validation and test sets for a given alpha. Next, graph in a lineplot the validation and test set perplexities for a range of alphas that reveals the full relationship between validation and test set perplexities. """

##TODO
import matplotlib.pyplot as plt
import numpy as np


def perplexities_from_alpha(alpha):
  ##your code here

   validation_perplexity=model.perplexity(validation_set)
   testset_perplexity=model.perplexity(test_set)
   return( (validation_perplexity,testset_perplexity) )

alphas = [i/10000 for i in range(1,10001)] ## populate the list of alpha values here -- choose carefully!
## your code for graphing the perplexities here
validation=[]
test=[]
for alpha in alphas: 
   model=bigram_model(alpha)
   model.train(training_set)
   (validation_perplexity , test_perplexity)=perplexities_from_alpha(alpha)
  #  print(alpha,validation_perplexity , test_perplexity)
   validation.append(validation_perplexity)    
   test.append(test_perplexity)
i_alpha_optim_val = np.argmin(validation)
alpha_optim = alphas[i_alpha_optim_val]
print("Optimal alpha for validation set : %s" % alpha_optim)
i_alpha_optim_test = np.argmin(test)
alpha_optim = alphas[i_alpha_optim_test]
print("Optimal alpha for test set : %s" % alpha_optim)
plt.xlabel("alpha")
plt.ylabel("perplexity")
plt.plot(alphas,validation, label="validation_perplexity")
plt.plot(alphas,test, label="test_perplexity")
plt.show()

"""### Interpret the results 

*   What value of Î± worked the best for the validation set? 
*   Was it the same that would have worked best for the test set?

**TODO**: Your answer

# Export to PDF

Run the following cell to download the notebook as a nicely formatted pdf file.
"""

# Add to a new cell at the end of the notebook and run the follow code, 
# which will save the notebook as pdf in your google drive (allow the permissions) and download it automatically.

!wget -nc https://raw.githubusercontent.com/scaperex/colab-pdf/master/colab_pdf.py

from colab_pdf import colab_pdf

# If you saved the notebook in the default location in your Google Drive,
#  and didn't change the name of the file, the code should work as is. If not, adapt accordingly.
# E.g. in your case the file name may be "Copy of XXXX.ipynb"

colab_pdf(file_name='Pset_2_Tuning_ngram_model.ipynb', notebookpath="drive/MyDrive/Colab Notebooks")